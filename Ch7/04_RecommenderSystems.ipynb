{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows an example recommendation system using doc2vec. We will use a dataset called CMU Book summaries [dataset](http://www.cs.cmu.edu/~dbamman/booksummaries.html). Alternateively, the dataset's link can be found in the `BookSummaries_Link.md` file under the Data folder in Ch7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/69/1262ed0050c21f5054702b8e96a2d8c310d4cd059e4a08c9a2fe6a5dae65/gensim-3.8.3-cp35-cp35m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.2MB 930kB/s ta 0:00:011   41% |█████████████▎                  | 10.1MB 5.2MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting smart-open>=1.8.1 (from gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/77/744c79da6e66691e3500b6dffff29bdd787015eae817d594791edc7b719b/smart_open-2.0.0.tar.gz (103kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 3.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /home/etherealenvy/miniconda3/envs/practicalnlp/lib/python3.5/site-packages (from gensim) (1.14.0)\n",
      "Collecting scipy>=0.18.1 (from gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/60/8cbf00c0deb50a971e6e3a015fb32513960a92867df979870a454481817c/scipy-1.4.1-cp35-cp35m-manylinux1_x86_64.whl (26.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.0MB 1.0MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting numpy>=1.11.3 (from gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/92/fa5295d9755c7876cb8490eab866e1780154033fa45978d9cf74ffbd4c68/numpy-1.18.4-cp35-cp35m-manylinux1_x86_64.whl (20.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.0MB 1.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/etherealenvy/miniconda3/envs/practicalnlp/lib/python3.5/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Collecting boto (from smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 4.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting boto3 (from smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/9e/e963605983fc1188c200ce84e2e07a1882c84a9e4c71cba80076b21441bb/boto3-1.13.4-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 6.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/etherealenvy/miniconda3/envs/practicalnlp/lib/python3.5/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/etherealenvy/miniconda3/envs/practicalnlp/lib/python3.5/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/etherealenvy/miniconda3/envs/practicalnlp/lib/python3.5/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/etherealenvy/miniconda3/envs/practicalnlp/lib/python3.5/site-packages (from requests->smart-open>=1.8.1->gensim) (2018.8.24)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/43/1e939e1fcd87b827fe192d0c9fc25b48c5b3368902bfb913de7754b0dc03/jmespath-0.9.5-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl\n",
      "Collecting botocore<1.17.0,>=1.16.4 (from boto3->smart-open>=1.8.1->gensim)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!pip install nltk\n",
    "#todo: add pip for downloading nltk data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset’s README to understand the data format. \n",
    "data_path = \"booksummaries.txt\"\n",
    "mydata = {} #titles-summaries dictionary object\n",
    "for line in open(data_path, encoding=\"utf-8\"):\n",
    "    temp = line.split(\"\\t\")\n",
    "    mydata[temp[2]] = temp[6]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the data for doc2vec, build and save a doc2vec model\n",
    "train_doc2vec = [TaggedDocument((word_tokenize(mydata[t])), tags=[t]) for t in mydata.keys()]\n",
    "model = Doc2Vec(vector_size=50, alpha=0.025, min_count=10, dm =1, epochs=100)\n",
    "model.build_vocab(train_doc2vec)\n",
    "model.train(train_doc2vec, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "model.save(\"d2v.model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Animal Farm', 0.6777619123458862), ('The Wild Irish Girl', 0.6119967699050903), (\"Snowball's Chance\", 0.60667884349823), ('Family Matters', 0.5831906199455261), ('Settlers in Canada', 0.582908570766449), ('Poor White', 0.5771366953849792), ('The Road to Omaha', 0.576944887638092), ('Ponni', 0.5766265988349915), (\"Family Guy: Stewie's Guide to World Domination\", 0.5674009323120117), ('Texas Fever', 0.5643234848976135)]\n"
     ]
    }
   ],
   "source": [
    "#Use the model to look for similar texts\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "#This is a sentence from the summary of “Animal Farm” on Wikipedia:\n",
    "#https://en.wikipedia.org/wiki/Animal_Farm\n",
    "sample = \"\"\"\n",
    "Napoleon enacts changes to the governance structure of the farm, replacing meetings with a committee of pigs who will run the farm.\n",
    " \"\"\"\n",
    "new_vector = model.infer_vector(word_tokenize(sample))\n",
    "sims = model.docvecs.most_similar([new_vector]) #gives 10 most similar titles\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
